{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11a56a4a04d7af2d7c03560cbb3038be5419f22c"
   },
   "source": [
    "Working with images is pretty memory consuming, especially if you read and preprocess all of them at the same time. The following approach avoids this problem in Keras, leaving more space in memory to use augmentation and/or loading pre-trained models. I hope this helps Kagglers to work on their networks in Kaggle kernels without worrying (or at least worrying less) with the 14GB of memory provided using GPU environment. I tried to comment the comment the code as clearer as I could, but if some part was not well-explained or if you have doubts, ask on the comments :) \n",
    "\n",
    "# Contents\n",
    "___\n",
    "1. [(Very) brief data exploration](#exploration)\n",
    "2. [Training models using generators and flow_from_dataframe](#flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d9c73ad23e6c2eae3028255ee00c3254fe66401"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2cea35de3530cc898be5b85063b84e875401d092"
   },
   "outputs": [],
   "source": [
    "os.listdir(\"../input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46a8839e13a14eb8d16ea6823de9927ea63d5001"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "67ae1f5ec310a945ab45d763a182b0018f883cff"
   },
   "source": [
    "# (Very) brief data exploration <a name=\"exploration\"></a>\n",
    "___ \n",
    "\n",
    "Let's see some whale images that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65a7b542f911fb4a0a2f614cecac205aa5a6358b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_path = '../input/train/'\n",
    "\n",
    "#get the first 5 whale images\n",
    "images = [(whale_img, whale_label) for (whale_img, whale_label) in zip(train_df.Image[:5], train_df.Id[:5])]\n",
    "\n",
    "fig, m_axs = plt.subplots(1, len(images), figsize = (20, 10))\n",
    "#show the images and label them\n",
    "for ii, c_ax in enumerate(m_axs):\n",
    "    c_ax.imshow(imread(os.path.join(img_path,images[ii][0])))\n",
    "    c_ax.set_title(images[ii][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c792fed9e252e589df2fa9961a55cfe9b9855741"
   },
   "source": [
    "At first the task seems 'simple' to begin with as this is a classification problem. The problem in this dataset is that there are 5005 kinds of whales (including the category new_whale). Since there are about 25k images, this gives us about 5 images of each whale on average, which is an extremely low number to train a model. But let's confirm that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "251dfe2fddcd12a2f2c6d5ccb6e66cd5d1410438",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#how many photos of each whale\n",
    "train_df.Id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "184ceb314a97e701f513c3fea32fea2a8ce41279"
   },
   "source": [
    "Now here we need to be careful. Several whales have been spotted considerably more times than others. Moreover, 9664 whales in the training dataset are actually non-identified whales. There are also many classes with only one image. I believe that correctly identifying (i.e. guessing a photo is one of them with a higher probability) those ones will define the top Kagglers in this competition. Now the fun begins. \n",
    "\n",
    "# Training models using generators and flow_from_dataframe <a name=\"flow\"></a>\n",
    "____\n",
    "\n",
    "In order to avoid using consuming so much memory, we will make use of the `fit_generator` method in our model. To use it, we have three options to get and train our data: `flow`, `flow_from_dataframe` and `flow_from_directory`.   [Here](https://keras.io/preprocessing/image/#imagedatagenerator-class/) you can check the full documentation and their arguments. \n",
    "\n",
    "The first method, `flow` is used when we already have all the data we need available in memory. Here, however, we only have the image's location in memory right now, and we don't want to load all images at the same time to avoid extra memory consumption. Therefore we won't use `flow`. \n",
    "\n",
    "The second one, `flow_from_dataframe` will be very useful to us. It checks the path available on the dataframe and then automatically search for the image in train directory. Then it make the desired preprocessing steps available in `ImageDataGenerator`. \n",
    "\n",
    "The last method, `flow_from_directory`, will be used during testing, since we don't have a dataframe containing all the image's paths to the test set. This method looks inside the directory and get `batch_size` images to make the classification. \n",
    "\n",
    "In order to use `flow_from_directory` in our test data, we can't just use \n",
    "```python \n",
    "'../input/test/' \n",
    "``` \n",
    "because the the folders need to be arranged in the following format:\n",
    "\n",
    "![directory_formta](https://cdn-images-1.medium.com/max/1000/1*HpvpA9pBJXKxaPCl5tKnLg.jpeg)\n",
    "[Source](https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720)\n",
    "\n",
    "So we will need to create a folder that contains a folder that contains our images. This will make our generator recognize that there is one class of images in the test dataset (think of it as an \"unlabeled\" class) so then we can get this data and use our classifier to predict their classes. Let's do this now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "7dc9a691b988465dd989e5f5e26c6927729daa74"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "#create directories\n",
    "os.mkdir('test_folder')\n",
    "os.mkdir('test_folder/test_images')\n",
    "\n",
    "# copy subdirectory example\n",
    "fromDirectory = \"../input/test\"\n",
    "toDirectory = \"test_folder/test_images\"\n",
    "\n",
    "copy_tree(fromDirectory, toDirectory, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b556eed9fa5adf2ca828b3ee850e5e69b9d90dea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "make sure all preprocessing done in the training \n",
    "image generator is done in test generator as well\n",
    "'''\n",
    "\n",
    "# validation_split sets the percentage of data generated\n",
    "# to be used in validation phase\n",
    "datagen=image.ImageDataGenerator(rescale=1./255, validation_split = 0.1)\n",
    "test_datagen = image.ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "'''\n",
    "Comments:\n",
    "- ImageDataGenerator will resize all images to target_size\n",
    "- x_col is the column where the images' names are\n",
    "- y_col is the column where the labels are\n",
    "- has_ext means that the images' names include a file extension, e.g. image_name.jpg\n",
    "- Here you can change the targe_size to resize all images to different shapes.\n",
    "Maybe larger images help in getting a better accuracy\n",
    "'''\n",
    "\n",
    "# since the datagen is splitted in training and validation,\n",
    "# make sure to set subsets correctly\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df, directory=\"../input/train/\", \n",
    "    x_col=\"Image\", y_col=\"Id\", has_ext=True, seed = 42,\n",
    "    class_mode=\"categorical\", target_size=(100,100), batch_size=32, subset = \"training\")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(dataframe=train_df, directory=\"../input/train/\", \n",
    "    x_col=\"Image\", y_col=\"Id\", has_ext=True, seed = 42,\n",
    "    class_mode=\"categorical\", target_size=(100,100), batch_size=32, subset = \"validation\")\n",
    "\n",
    "# make sure shuffle is set to false, so the predictions are done on the same order\n",
    "# as they appear on the directory. batch_size should be 1 to make the\n",
    "# predictions image by image\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory=\"test_folder\", \n",
    "    seed = 42, class_mode=None, target_size=(100,100), batch_size=1, shuffle = False)\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "962d6da478a301d615354486af46a4f208d952e1"
   },
   "source": [
    "Next let's build, compile and train the model. Here I'll use a simple Convolutional layer, Dropout and GlobalMaxPooling for the sake of simplicity. You can plug your model right here and test it! Just make sure `input_shape` from Conv2D is the same that `target_size` in the generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16a9ccbecde62d9c1a057efa50281f2eb7df14b1"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "''' the function top_5_accuracy is from Peter's kernel:\n",
    "    https://www.kaggle.com/pestipeti/keras-cnn-starter\n",
    "'''\n",
    "def top_5_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (100, 100, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalMaxPooling2D()) \n",
    "# model.add(Flatten())\n",
    "model.add(Dense(5005, activation = 'softmax'))\n",
    "# model.summary()\n",
    "\n",
    "model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['accuracy', top_5_accuracy])\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "checkpointer = ModelCheckpoint(filepath='weights.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=2, callbacks = [checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e62c51a5ece0501aeed8f3bde7489e6955a3fa7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we need to use .reset() here otherwise\n",
    "#the other of predictions will be different\n",
    "#then the expected\n",
    "test_generator.reset()\n",
    "pred = model.predict_generator(test_generator,verbose = 1,steps=7960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88d6231548b14af35ae5bd576225160d05dfef33",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''This filters only the top 5 possible ids of an image'''\n",
    "pred_sorted = np.argsort(-pred, axis = 1)[:,:5]\n",
    "pred_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9310827f1787a20556c9333a93bc965dbfe8f0f7"
   },
   "source": [
    "Note that our model has clearly overfit. Indexes 3, 265 and 166 are the most common indexes in our training dataset (3 is new_whale). In fact, this overfit was expected because I didn't augment the data yet and the network was kept really really simple just to use it as a proxy for a real well-thought network. \n",
    "Some basic augmentation can be done within `ImagedataGenerator`. Check the [documentation](https://keras.io/preprocessing/image/) for some ideas!\n",
    "\n",
    "Now let's proceed to the final steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2d7ae2815556f6109757e23f19a7f12dc112c87"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now we generate a map of each \n",
    "index to an Id on the format \n",
    "{\n",
    "0: 'w_f48451c',\n",
    "1: 'w_c3d896a',\n",
    "2: 'w_20df2c5',\n",
    "...\n",
    "}\n",
    "'''\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10cede985340f4d2c18534085fe77370ef866d04"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Here we prepare pred_ids, which is a list of lists containing \n",
    "the top 5 ids by name. For example, w_13ae3d4. \n",
    "'''\n",
    "from tqdm import tqdm\n",
    "#create empty list\n",
    "pred_ids = list()\n",
    "for i,row in enumerate(tqdm(pred_sorted)):\n",
    "    #create a temporary list to store the ids for a given image\n",
    "    temp_list = []\n",
    "    for j,value in enumerate(row):\n",
    "        #for each index in pred_sorted, append the real Id in temp_list\n",
    "        temp_list.append(labels[row[j]])\n",
    "    #append all 5 ids for a given image to pred_ids\n",
    "    #effectively creating a similar list to pred_sorted\n",
    "    #but with the real ids\n",
    "    pred_ids.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df9cc9d2cac8e33f8b22d4661e90bdf5489f2511"
   },
   "outputs": [],
   "source": [
    "'''create the final predictions by using all ids in a single string'''\n",
    "final_preds = []\n",
    "for i,top_5_ids in enumerate(pred_ids):\n",
    "    final_preds.append(' '.join(pred_ids[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5daa8430d7bc301110623e0db49de10cdb63a003"
   },
   "outputs": [],
   "source": [
    "'''delete the files on disk - otherwise the Kaggle kernel will throw an error'''\n",
    "import shutil\n",
    "shutil.rmtree('test_folder', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47cc8b430b81f400f685d7f03ecfe20cc08035e5"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"Image\": os.listdir('../input/test'), \"Id\": final_preds})\n",
    "submission.to_csv(\"submission.csv\", index = False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
