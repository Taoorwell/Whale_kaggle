{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b95773e3f997e10b54fb9ff8cc0f4c19649aac21"
   },
   "source": [
    "We all like to play around with data and get things done. In this kernel I'll show you how you can do it yourself.\n",
    "## Full Video Explanation of this Notebook\n",
    "[KAGGLE KERNELS 2019](https://www.youtube.com/watch?v=AXcTm4gFerE)\n",
    "\n",
    "I also have a full explanation on how to work with large Image datasets ( like this one :D ) \n",
    "[How to Deal with Large Image Datasets](https://www.youtube.com/watch?v=myYMrZXpn6U)\n",
    "\n",
    "## Notebook Content\n",
    "1. [Resources](#zeroth-bullet)\n",
    "2. [Some libraries we need to get things done](#first-bullet)\n",
    "3. [How to load the dataset](#second-bullet)\n",
    "4. [Looking at 5 random beauties](#third-bullet)\n",
    "5. [Preprocessing the data](#forth-bullet)<br/>\n",
    "     5.1 [Using python OpenCV](#forth1-bullet)<br/>\n",
    "     5.2 [Using torchvision](#forth2-bullet)<br/>\n",
    "6. [Cleaning the Data](#fifth-bullet)\n",
    "7. [Encoding](#fifth-bullet)\n",
    "8. [Handling the dataset](#sixth-bullet)\n",
    "9. [Building a very simple sequential model](#seventh-bullet)\n",
    "10. [Conclusion](#eighth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19e87d7741b836281b2bc24e5a5b23ce4779ff08"
   },
   "source": [
    "### Resources <a class=\"anchor\" id=\"zeroth-bullet\"></a>\n",
    "I'm currently making a video series explaining step by step this kernel, if this sounds interesting, here are the links \n",
    "1. [Introduction](https://www.youtube.com/watch?v=pD_IR72g5tE&t=1s)\n",
    "2. [Libraries](https://www.youtube.com/watch?v=2iRIPjXTGeY&t=1s) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b54aa34e77a39a4c864b533e577a9cf8565158d"
   },
   "source": [
    "### Some libraries we need to get things done <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed191b99b82410112505c26ac5568069af621000"
   },
   "source": [
    "### Working with files\n",
    "It's always a pain in the ass to work with paths, when I was starting I almost have all my paths hardcoded. When working with teams I saw that this approach isn't get me anywhere, it's always, ok, in most cases, a great idea to store your general paths into variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "print(os.listdir('../input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "b7591856ae9cf424679b6485db1f65700ee41f18",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Youth-AI\\\\input\\\\train.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train_path = os.path.abspath('../input/train')\n",
    "img_test_path = os.path.abspath('../input/test')\n",
    "csv_train_path = os.path.abspath('../input/train.csv')\n",
    "csv_train_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "237d5dc7f70f83858067789f6b23cd06f894e99f"
   },
   "source": [
    "### How to load the dataset <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "We'll use here the [Pandas](https://pandas.pydata.org/pandas-docs/stable/) to load the dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "cd7fac33136c9a7e44578940f590e855ce020f43"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_train_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae7db9eded67319f72b300bd6c9e3a0656945a96"
   },
   "source": [
    "We can see that we have the paths of the images and the labels associated with the whales. To easy the image reading process we can create a aditional column to the dataset with the global path of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "531964c6933a4c6be51aca9820398d650006fb5b"
   },
   "outputs": [],
   "source": [
    "df['Image_path'] = [os.path.join(img_train_path,whale) for whale in df['Image']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4340760de73ee433710622c2fbe41790f182d1dd"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c46738add46adc9cb07eeac11538edfe7366a44f"
   },
   "source": [
    "### Looking at 5 random beauties  <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "It's a great deal of fun to explore the data and play around with *matplotlib*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34d4cd3d24022ac395cfee7f34ed60f5b73547ad"
   },
   "outputs": [],
   "source": [
    "full_path_random_whales = np.random.choice(df['Image_path'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b337d50f6ba17f6f12bdc0c8a61265be176fcca"
   },
   "outputs": [],
   "source": [
    "full_path_random_whales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73c9dc60723e69d2536694684355603cecd8178b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for whale in full_path_random_whales:\n",
    "    img = Image.open(whale)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8719866bb4625f1d169bb37af118ce411bb1fa44"
   },
   "source": [
    "### Preprocessing the data <a class=\"anchor\" id=\"forth-bullet\"></a>\n",
    "I could find some cool resources to help me put all this together. You'll find it extremely usefull\n",
    "* [DATA LOADING AND PROCESSING TUTORIAL](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)\n",
    "* [Lecture Notes: Basic Image Processing](https://www.cs.virginia.edu/~vicente/recognition/notebooks/image_processing_lab.html)\n",
    "* [PyTorch quick start: Classifying an image](http://blog.outcome.io/pytorch-quick-start-classifying-an-image/)\n",
    "\n",
    "\n",
    "Here we're going to use 2 approaches, basic OpenCv and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92ae34854974bd5fe683235587e62b5de40ffee1"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f9bcee9a05e30052b185f0d4df3ac1e1865b998"
   },
   "source": [
    "#### Using python OpenCV <a class=\"anchor\" id=\"forth1-bullet\"></a>\n",
    "OpenCV is a great, great, computer vision library. Here I just use the basics of it, but you can go wild with OpenCv. We are going to use to scale the images down and convert to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81bd1108a45ca6334045bfcbc2530cbb31efb410"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(full_path_random_whales[0])\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "res = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(res,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ef605051312751928b140aa6fe38af821b2ad58"
   },
   "source": [
    "#### Using torchvision <a class=\"anchor\" id=\"forth2-bullet\"></a>\n",
    "PyTorch is a library developed by Facebook, the torchvision module has some convenient features, like we're using here\n",
    "* Convert to grayscale\n",
    "* Resize\n",
    "* Corp\n",
    "* Transform to tensor\n",
    "* Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df55e56322ec96daefc422b86a4cea5ffca7f9d6"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Grayscale(num_output_channels=1),\n",
    "   transforms.Resize(128),\n",
    "   transforms.CenterCrop(128),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "imgs = [Image.open(whale) for whale in full_path_random_whales]\n",
    "imgs_tensor = [preprocess(whale) for whale in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e718f5b47b5c7226960d534a2d8c9c74fa286126"
   },
   "outputs": [],
   "source": [
    "imgs_tensor[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fcb3d91a5378e3494b55507d1bc6bfd1c460ddf"
   },
   "outputs": [],
   "source": [
    "img = imgs_tensor[0]\n",
    "plt.imshow(img[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47f6fa6842f01866761a2f0f7af7e168e773d702"
   },
   "source": [
    "### Cleaning the Data <a class=\"anchor\" id=\"fifth-bullet\"></a>\n",
    "[Why removing new_whale is a good idea](https://www.kaggle.com/suicaokhoailang/removing-class-new-whale-is-a-good-idea)\n",
    "\n",
    "Working with biases datasets is a huge problem, you can look more in this blog I posted a while ago also using data from a Kaggle competition \n",
    "\n",
    "[Why you should care about bias.](https://jhonatandasilva.com/bias-in-ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db7521ae4dc62b96980a9dae56e6fa18d41189bd"
   },
   "outputs": [],
   "source": [
    "df.Id.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6cffe02397ac009979c88d500fae0e0bdbbbe980"
   },
   "source": [
    "We can create a new dataframe just for testing purposes without the new_whale class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f62127c324b48331ab1d5675e1f17c72ebff3a26"
   },
   "outputs": [],
   "source": [
    "I_dont_want_new_whales = df['Id'] != 'new_whale'\n",
    "df = df[I_dont_want_new_whales]\n",
    "df.Id.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ba3c7eadbf49b79f166bf8ed731bd4b0ae0a335"
   },
   "source": [
    "### Encoding <a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "To further use torchvision we need to encode our data, here's how you can do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91cf4c1957c63305158fc2a22934e770f6cb7b9b"
   },
   "outputs": [],
   "source": [
    "unique_classes = pd.unique(df['Id'])\n",
    "encoding = dict(enumerate(unique_classes))\n",
    "encoding = {value: key for key, value in encoding.items()}\n",
    "df = df.replace(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4251b223f858bd063b092f41cd0f376837af13f0"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0de2f6f5ea7089df7df297daa97e07baed981d76"
   },
   "source": [
    "### Handling the dataset <a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "(Don't do this in your personal computer, this isn't a great way to open your images, just for test purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b56bd9b5fbaaaf9494d693ec2de76d79bfb539b5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0274012ef5d32de0d07ffbbed3a5fcb73ef33740"
   },
   "source": [
    "#### Simple model\n",
    "As we are going to construct a simple sequencial linear model we will load just 1000 images to test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e7e9ea12194a2e1b2d7ffb42f92a6724bf0bbfe"
   },
   "outputs": [],
   "source": [
    "test = df['Image_path'][:1000]\n",
    "imgs = [Image.open(whale) for whale in test]\n",
    "imgs_tensor = torch.stack([preprocess(whale) for whale in imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "981abaa66655138e391d74731377c55107b6105f"
   },
   "outputs": [],
   "source": [
    "labels = torch.tensor(df['Id'][:1000].values)\n",
    "max_label = int(max(labels)) +1\n",
    "max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "299470e7dfeddf025660ceba60eee62856162da7"
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgs_tensor[0].reshape(128,128),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca40a7803024d5269b28e7abc1de483d52b5cfac"
   },
   "source": [
    "### Building a very simple sequential model <a class=\"anchor\" id=\"seventh-bullet\"></a>\n",
    "\n",
    "This is a great way to play around if you are a begginner in the area. If you don't know much from building Neural Networks I have a few resources \n",
    "\n",
    "1. [Creating a Perceptron](https://jhonatandasilva.com/build-your-own-perceptron/)\n",
    "2. [What are the building blocks of Deep Learning](https://jhonatandasilva.com/perceptrons/) \n",
    "3. [Play around with Neural Nets](https://jhonatandasilva.com/play-with-nn/)\n",
    "4. [Training your Neural Net](https://jhonatandasilva.com/training-your-neural-networks/)\n",
    "5. [When all comes together](https://jhonatandasilva.com/mnist-pytorch/) \n",
    "\n",
    "Exploring more on the Vision side there's also\n",
    "\n",
    "1. [How Neural Nets sees the world ](https://jhonatandasilva.com/how-nn-sees-the-world/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3108ef8c4d373e869f185f9974d2307233ee788"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(128*128, 256),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(128, max_label),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5f31c1983f38f667cc2cc55867df45db7e9479c"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 10\n",
    "iters = int(len(imgs_tensor)/batch_size)\n",
    "next_batch = 0\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    next_batch = 0\n",
    "    for n in range(iters):\n",
    "        batch_images = imgs_tensor[next_batch:next_batch+batch_size] \n",
    "        batch_images = batch_images.view(batch_images.shape[0], -1)\n",
    "        batch_labels = labels[next_batch:next_batch+batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch_images)\n",
    "        loss = criterion(output, batch_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        next_batch += batch_size\n",
    "        \n",
    "    print(running_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
